{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Homework 01 - Instructions\n",
    "\n",
    "- The goal for this lab will be to collect some data from you and get you some experience in working with Github and Jupyter Notebooks. We are going to also learn the basics of loading data into Python.\n",
    "- We will go over importing data from a number of different file types.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Importing a CSV File\n",
    "- This is obviously a very common technique which we will use over and over.  Luckily, someone has written a `csv` package that does the majority of the heavy lifting. \n",
    "- `import csv` imports all methods in the csv package.  \n",
    "- We are going to import the values from the csv into a specific type of Python data structure, a `list`. Declaring `listcsv=[]` initializes the objects as a list and makes available the `append` method.  \n",
    "- By using the `with open` syntax shown below, we don't have to open and then close the data structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CSV\n",
    "- Comma delimited files are a common way of transmitting data. \n",
    "- Data for different columns is separated by a comma.\n",
    "- Open the CSV file in a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Importing a CSV File\n",
    "- The `open` command specifies the file name and what we want to do with it, here `r` stand for read.\n",
    "- The `csvreader` is an object which iterates on the file. \n",
    "- We then read each `row` using a `for` loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each row of the reader imported as a: <class 'list'> ['\\ufefffirst-name', 'last-name', 'email-rpi', 'email-other', 'github-userid', 'slack-userid'] \n",
      "\n",
      "each row of the reader imported as a: <class 'list'> ['Jason', 'Kuruzovich', 'kuruzj@rpi.edu', 'jkuruzovich@gmail.com', 'jkuruzovich', 'jason_kuruzovich'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This is an example of how to import a CSV into a Python list. \n",
    "import csv  #This imports the CSV package.\n",
    "listcsv=[] #This initializes a list data structure.\n",
    "\n",
    "with open('in/name.csv', 'r') as data_file:   #The \"with\" incorporates an open and close of file. \n",
    "    csvreader = csv.reader(data_file, delimiter=',')\n",
    "    for row in csvreader:\n",
    "        print(\"each row of the reader imported as a:\", type(row), row,\"\\n\")\n",
    "        listcsv.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reassigning variables programiatically. \n",
    "- `listcsv` is a 2 dimensional list, with the first number indicating the row and the second number indicating the column.\n",
    "- Objects start numbering at 0, so that in this case the header-row is 0. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#q1. Updated ALL values of list  (with your infoormation) (1 pt).\n",
    "#Here is how you update your list.  Updated ALL values.  \n",
    "listcsv[1][0] = \"Yirong\"   #row/column numbers start at 0\n",
    "listcsv[1][1] = \"Tang\"    #row/column numbers start at 0\n",
    "listcsv[1][2] = \"tangy8@rpi.edu\"\n",
    "listcsv[1][3] = \"tyrvivian@hotmail.com\"\n",
    "listcsv[1][4] = \"tyrvivian\"\n",
    "listcsv[1][5] = \"yirong tang\"\n",
    "#...(update the rest of the variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Output the CSV File\n",
    "- Here, notice we are doing just the same thing as reading. However, we are doing it by opening with a `w`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we are going to save as a tab delimited file\n",
    "with open(\"out/name.csv\", 'w' ) as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=',')\n",
    "    writer.writerows(listcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Writing a Tab Delimited file\n",
    "- Here we are able to output the file as a tab delimited file.  \n",
    "- A tab delimed file utilizes '\\t' as the delimiter.\n",
    "- Update the file below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we are going to save as a tab delimited file\n",
    "with open(\"out/name.txt\", 'w') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter='\\t')\n",
    "    writer.writerows(listcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Importing CSV into a Pandas Dataframe\n",
    "- Data structured like CSV's is extremely common\n",
    "- We are going to use a special package called Pandas which will give access to many useful methods for working with data.  \n",
    "- `pandas` is often imported as the abbreviated `pd`.\n",
    "- Typing the object name of a pandas dataframe (here `dfcsv`) gives a *pretty printed* version of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first-name</th>\n",
       "      <th>last-name</th>\n",
       "      <th>email-rpi</th>\n",
       "      <th>email-other</th>\n",
       "      <th>github-userid</th>\n",
       "      <th>slack-userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason</td>\n",
       "      <td>Kuruzovich</td>\n",
       "      <td>kuruzj@rpi.edu</td>\n",
       "      <td>jkuruzovich@gmail.com</td>\n",
       "      <td>jkuruzovich</td>\n",
       "      <td>jason_kuruzovich</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first-name   last-name       email-rpi            email-other github-userid  \\\n",
       "0      Jason  Kuruzovich  kuruzj@rpi.edu  jkuruzovich@gmail.com   jkuruzovich   \n",
       "\n",
       "       slack-userid  \n",
       "0  jason_kuruzovich  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will load the local name.csv file into a Pandas dataframe.  We will work with these a lot in the future.\n",
    "import pandas as pd # This line imports the pandas package. \n",
    "dfcsv = pd.read_csv('in/name.csv')\n",
    "dfcsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice the Pandas Magic! \n",
    "- Pandas figured out that you have columns and even knows the rows. \n",
    "- We can update the files via loc or i-loc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first-name</th>\n",
       "      <th>last-name</th>\n",
       "      <th>email-rpi</th>\n",
       "      <th>email-other</th>\n",
       "      <th>github-userid</th>\n",
       "      <th>slack-userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yirong</td>\n",
       "      <td>tang</td>\n",
       "      <td>tangy8@rpi.edu</td>\n",
       "      <td>tyrvivian@hotmail.com</td>\n",
       "      <td>tyrvivian</td>\n",
       "      <td>yirong tang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first-name last-name       email-rpi            email-other github-userid  \\\n",
       "0     yirong      tang  tangy8@rpi.edu  tyrvivian@hotmail.com     tyrvivian   \n",
       "\n",
       "  slack-userid  \n",
       "0  yirong tang  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we have 2 ways of updating the file. First \n",
    "dfcsv.loc[0, 'first-name'] = 'yirong'\n",
    "dfcsv.loc[0, 'last-name'] = 'tang'\n",
    "dfcsv.loc[0, 'email-rpi'] = 'tangy8@rpi.edu'\n",
    "dfcsv.loc[0, 'email-other'] = 'tyrvivian@hotmail.com'\n",
    "dfcsv.loc[0, 'github-userid'] = 'tyrvivian'\n",
    "dfcsv.loc[0, 'slack-userid'] = 'yirong tang'\n",
    "dfcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This just utilizes the integer position. \n",
    "dfcsv.iloc[0, 0] = 'your first via iloc'\n",
    "dfcsv.iloc[0, 1] = 'your last via iloc'\n",
    "dfcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update the remainder of the information using the loc method of Pandas. \n",
    "# Notice how we can just as easily write the file. \n",
    "dfcsv = dfcsv.to_csv('out/namepd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "- Javascript object notation.  \n",
    "- This enables multipled layers of nesting, something that could take multiple files in a CSV or relational tables.\n",
    "- JSON is often used for APIs.\n",
    "- Our JSON is imported as a `dictionary`, which is another internal type of Python data structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is a python object of type:  <class 'dict'> \n",
      "\n",
      "{'student': [{'email-other': 'jkuruzovich@gmail.com',\n",
      "              'email-rpi': 'kuruzj@rpi.edu',\n",
      "              'first-name': 'Jason',\n",
      "              'github-userid': 'jkuruzovich',\n",
      "              'last-name': 'Kuruzovich',\n",
      "              'slack-userid': 'jason_kuruzovich'}]}\n"
     ]
    }
   ],
   "source": [
    "import json   #This imports the JSON\n",
    "from pprint import pprint  #This will print the file in a nested way. \n",
    "\n",
    "with open('in/name.json') as data_file:   #The \"with\" incorporates an open and close of file.   \n",
    "    datajson = json.load(data_file)\n",
    "\n",
    "print(\"data is a python object of type: \", type(datajson),\"\\n\")\n",
    "pprint(datajson) #Pretty printing (pprint) makes it easier to see the nesting of the files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'student': [{'email-other': 'tyrvivian@hotmail.com',\n",
      "              'email-rpi': 'tangy8@rpi.edu',\n",
      "              'first-name': 'Yirong',\n",
      "              'github-userid': 'tyrvivian',\n",
      "              'last-name': 'Tang',\n",
      "              'slack-userid': 'yirong tang'}]}\n"
     ]
    }
   ],
   "source": [
    "#Here is how you update the dictionary: \n",
    "#We are indicating that we want the first student, and from there we list which \"key\" for \n",
    "#the dictionary we want (i.e., 'first-name').\n",
    "# Update the rest of the information with your \n",
    "\n",
    "datajson['student'][0]['first-name']  = 'Yirong'\n",
    "datajson['student'][0]['last-name']  = 'Tang'\n",
    "datajson['student'][0]['email-other']  = 'tyrvivian@hotmail.com'\n",
    "datajson['student'][0]['email-rpi']  = 'tangy8@rpi.edu'\n",
    "datajson['student'][0]['github-userid']  = 'tyrvivian'\n",
    "datajson['student'][0]['slack-userid']  = 'yirong tang'\n",
    "pprint(datajson)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json   #This imports the JSON\n",
    "from pprint import pprint  #This will print the file in a nested way. \n",
    "\n",
    "with open('out/name.json', 'w') as data_file:   #The \"with\" incorporates an open and close of file.   \n",
    "    json.dump(datajson, data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parquet Files\n",
    "- CSV files are great for humans to read and understand.  \n",
    "- For \"big data\" though, it isn't a great long term storage option (inefficient/slow).\n",
    "- Parquet is a type columnar storage format.  It makes dealing with lots of columns fast. \n",
    "- [fastparquet](https://fastparquet.readthedocs.io) is a Python package for dealing with Parquet files. \n",
    "- Apache Spark also natively reads Parquet Files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first-name</th>\n",
       "      <th>last-name</th>\n",
       "      <th>email-rpi</th>\n",
       "      <th>email-other</th>\n",
       "      <th>github-userid</th>\n",
       "      <th>slack-userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason</td>\n",
       "      <td>Kuruzovich</td>\n",
       "      <td>kuruzj@rpi.edu</td>\n",
       "      <td>jkuruzovich@gmail.com</td>\n",
       "      <td>jkuruzovich</td>\n",
       "      <td>jason_kuruzovich</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first-name   last-name       email-rpi            email-other github-userid  \\\n",
       "0      Jason  Kuruzovich  kuruzj@rpi.edu  jkuruzovich@gmail.com   jkuruzovich   \n",
       "\n",
       "       slack-userid  \n",
       "0  jason_kuruzovich  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastparquet import ParquetFile\n",
    "pf = ParquetFile('in/name.parq')\n",
    "dfparq = pf.to_pandas()\n",
    "dfparq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'student': [{'email-other': 'tyrvivian@hotmail.com',\n",
      "              'email-rpi': 'tangy8@rpi.edu',\n",
      "              'first-name': 'Yirong',\n",
      "              'github-userid': 'tyrvivian',\n",
      "              'last-name': 'Tang',\n",
      "              'slack-userid': 'yirong tang'}]}\n"
     ]
    }
   ],
   "source": [
    "#Update the dfparq dataframe (same code as Pandas)\n",
    "datajson['student'][0]['first-name']  = 'Yirong'\n",
    "datajson['student'][0]['last-name']  = 'Tang'\n",
    "datajson['student'][0]['email-other']  = 'tyrvivian@hotmail.com'\n",
    "datajson['student'][0]['email-rpi']  = 'tangy8@rpi.edu'\n",
    "datajson['student'][0]['github-userid']  = 'tyrvivian'\n",
    "datajson['student'][0]['slack-userid']  = 'yirong tang'\n",
    "pprint(datajson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can similarly easily write to a .parq file. \n",
    "from fastparquet import write\n",
    "write('out/name.parq', dfparq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Rubric\n",
    "The following Rubric will be used to grade homwork. \n",
    "q1. Updated `out/name.csv` file with your infoormation  (2 pt).<br>\n",
    "q2. Updated `out/name.txt` file with your infoormation  (2 pt).<br>\n",
    "q3. Updated `out/name.csv` file with your infoormation  (2 pt).<br>\n",
    "q4. Updated `out/name.json`  file with your infoormation  (2 pt).<br>\n",
    "q5. Updated `out/name.parq` parquet file (2 pt)<br>\n",
    "q6. Review the [pandas documentation](https://pandas.pydata.org) and descripe 3 cool things that Pandas can do.  (2 pt) <br>\n",
    "q7. Describe the difference between the loc and iloc with accessing a Pandas dataframe. \n",
    "q8. Let's say you had this sample data in json.  Show (conceptually) how you would go about changing this to a CSV file. Your output should just list the structure of the data file. \n",
    "```{json}\n",
    "myObj = {\n",
    "    \"name\":\"John\",\n",
    "    \"age\":30,\n",
    "    \"cars\": {\n",
    "        \"car1\":\"Ford\",\n",
    "        \"car2\":\"BMW\",\n",
    "        \"car3\":\"Fiat\"\n",
    "    }\n",
    " }\n",
    "\n",
    "```\n",
    "q9.  Read through the [fastparquet documentation](https://fastparquet.readthedocs.io) \n",
    "q10. Agreement with statement: \"I work through this entire homework step by step.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Notice how we can use 3 quotes. \n",
    "q6 = \"\"\"q6.  \n",
    "1. .groupby() allows to reference either column names or index level names, \n",
    "so the column names and index level names could be grouped together, which is much easier.\n",
    "\n",
    "2. it discard the panel and use 2-level MultiIndexed DataFrame when useing the\n",
    ".rolling(..), .expanding(..), or .ewm(..), so the new talbe are easier to read.\n",
    "\n",
    "3. the pandas create a new type of numerical index,UInt64Index; and it could support more \n",
    "operations of unsigned, or purely non-negative, integers which was not supported before.\n",
    "   \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q7 = \"\"\"q7.\n",
    "'loc' works on labels in the index.\n",
    "'iloc' works on the positions in the index (so it only takes integers).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q8 = \"\"\"q8.\n",
    "import csv\n",
    "import json \n",
    "\n",
    "\n",
    "myObj=[\n",
    "    {\n",
    "    \"name\":\"John\",\n",
    "    \"age\":30,\n",
    "    \"cars\": {\n",
    "        \"car1\":\"Ford\",\n",
    "        \"car2\":\"BMW\",\n",
    "        \"car3\":\"Fiat\"\n",
    "        }\n",
    "    }\n",
    "    ]\n",
    "    \n",
    "myObj1=json.dumps(myObj)\n",
    "myObj_data = json.loads(myObj1)\n",
    "f = csv.writer(open(\"test_str.csv\", \"w\"))\n",
    "\n",
    "#csvwriter = csv.writer(myObj)\n",
    "\n",
    "for myObj in myObj_data:\n",
    "    f.writerow([myObj[\"name\"],\n",
    "    myObj[\"age\"],\n",
    "    myObj[\"cars\"][\"car1\"],\n",
    "    myObj[\"cars\"][\"car2\"],\n",
    "    myObj[\"cars\"][\"car3\"]\n",
    "               ])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q9 = \"\"\"q9.\n",
    "The reading is finished\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#q10 I work throug this entire homework step by step. Change to True if you did. \n",
    "\n",
    "q10= \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers= [q6,q7,q8,q9,q10]\n",
    "with open('out/answers.txt', 'w') as outfile:   #The \"with\" incorporates an open and close of file. \n",
    "    outfile.write(\"\\n\".join(answers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This work is licensed under the [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/) license agreement."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "environment": "py3k",
   "summary": "A test Jupyter notebook to verify local Python Environment.",
   "url": "https://anaconda.org/analyticsdojo/local-intro"
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
